{
  "model": "google/gemma-2b",
  "total_params": 2506176514,
  "model_size_mb": 9560.304695129395,
  "best_f1": 0.7898319175601458,
  "best_epoch": 3,
  "total_training_time_sec": 2350.371519804001,
  "avg_time_per_epoch_sec": 470.0743039608002,
  "training_metrics": {
    "epochs": [
      1,
      2,
      3,
      4,
      5
    ],
    "train_loss": [
      0.20805754295878612,
      0.14464908293531428,
      0.09122887420862791,
      0.04172553594731336,
      0.020199808059579633
    ],
    "train_time_sec": [
      420.1135365962982,
      420.4215898513794,
      421.4416527748108,
      421.0881941318512,
      421.37633752822876
    ],
    "val_f1": [
      0.7779037020799341,
      0.780735255716484,
      0.7898319175601458,
      0.782894809226901,
      0.7860467143820186
    ],
    "val_precision": [
      0.8205368366567051,
      0.8260039662865438,
      0.7783505154639008,
      0.7809136517337995,
      0.7733898013586558
    ],
    "val_recall": [
      0.7394819849837679,
      0.7401705984272794,
      0.8016571149317873,
      0.7848860455817499,
      0.7991247945266161
    ],
    "val_tp": [
      33290,
      33321,
      36089,
      35334,
      35975
    ],
    "val_fp": [
      7281,
      7019,
      10277,
      9913,
      10541
    ],
    "val_fn": [
      11728,
      11697,
      8929,
      9684,
      9043
    ],
    "peak_memory_mb": [
      47824.8955078125,
      47824.9658203125,
      47824.9658203125,
      47824.9658203125,
      47824.9658203125
    ]
  }
}