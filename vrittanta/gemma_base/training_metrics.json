{
  "model": "google/gemma-2b",
  "total_params": 2506176514,
  "model_size_mb": 9560.304695129395,
  "best_f1": 0.844300026578428,
  "best_epoch": 3,
  "total_training_time_sec": 4609.656150102615,
  "avg_time_per_epoch_sec": 921.9312300205231,
  "training_metrics": {
    "epochs": [
      1,
      2,
      3,
      4,
      5
    ],
    "train_loss": [
      0.08304890728637791,
      0.03229372072782863,
      0.016401342202153557,
      0.013466176933166792,
      0.011319693026413986
    ],
    "train_time_sec": [
      847.3462316989899,
      849.4600079059601,
      847.8655638694763,
      848.8263530731201,
      848.7015271186829
    ],
    "val_f1": [
      0.84051838088182,
      0.8411214948268586,
      0.844300026578428,
      0.8124621894601592,
      0.8326682623367908
    ],
    "val_precision": [
      0.7944999999996027,
      0.8239095315019795,
      0.8153765690372304,
      0.8806557377043406,
      0.7912032355911066
    ],
    "val_recall": [
      0.8921953958445299,
      0.8590679393594278,
      0.8753509264453254,
      0.7540707467710533,
      0.8787198203251664
    ],
    "val_tp": [
      1589,
      1530,
      1559,
      1343,
      1565
    ],
    "val_fp": [
      411,
      327,
      353,
      182,
      413
    ],
    "val_fn": [
      192,
      251,
      222,
      438,
      216
    ],
    "peak_memory_mb": [
      47824.8955078125,
      47824.9306640625,
      47824.9306640625,
      47824.9306640625,
      47824.9306640625
    ]
  }
}