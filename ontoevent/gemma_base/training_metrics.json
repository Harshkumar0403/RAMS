{
  "model": "google/gemma-2b",
  "total_params": 2506176514,
  "model_size_mb": 9560.304695129395,
  "best_f1": 0.7881856535105983,
  "best_epoch": 3,
  "total_training_time_sec": 2188.176570892334,
  "avg_time_per_epoch_sec": 437.6353141784668,
  "training_metrics": {
    "epochs": [
      1,
      2,
      3,
      4,
      5
    ],
    "train_loss": [
      0.14315305243338078,
      0.038191592516246396,
      0.03207925669996488,
      0.02723581055033719,
      0.025305530464646207
    ],
    "train_time_sec": [
      398.3448312282562,
      401.40513038635254,
      401.11449337005615,
      401.36892318725586,
      401.4004328250885
    ],
    "val_f1": [
      0.7679558006035581,
      0.7693744159319013,
      0.7881856535105983,
      0.7757352936162227,
      0.7623485549506561
    ],
    "val_precision": [
      0.7679558011035581,
      0.7803030303015525,
      0.7274143302169355,
      0.7743119266040839,
      0.7716981132060912
    ],
    "val_recall": [
      0.7679558011035581,
      0.75874769797282,
      0.8600368324109392,
      0.7771639042342963,
      0.7532228360943771
    ],
    "val_tp": [
      417,
      412,
      467,
      422,
      409
    ],
    "val_fp": [
      126,
      116,
      175,
      123,
      121
    ],
    "val_fn": [
      126,
      131,
      76,
      121,
      134
    ],
    "peak_memory_mb": [
      47824.8955078125,
      47825.0009765625,
      47825.0009765625,
      47825.0009765625,
      47825.0009765625
    ]
  }
}