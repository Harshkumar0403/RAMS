{
  "model": "google/gemma-2b",
  "total_params": 2506176514,
  "model_size_mb": 9560.304695129395,
  "best_f1": 0.7226209043362792,
  "best_epoch": 2,
  "total_training_time_sec": 5433.016839027405,
  "avg_time_per_epoch_sec": 1086.603367805481,
  "training_metrics": {
    "epochs": [
      1,
      2,
      3,
      4,
      5
    ],
    "train_loss": [
      0.039388597681478225,
      0.012080447193885764,
      0.0074949171664665795,
      0.00521827548017235,
      0.0035635029543862502
    ],
    "train_time_sec": [
      1041.6513028144836,
      1042.8612260818481,
      1041.9699881076813,
      1041.7738468647003,
      1041.6958365440369
    ],
    "val_f1": [
      0.6911357335742379,
      0.7226209043362792,
      0.7125372141872495,
      0.6936813181829263,
      0.6899592939377674
    ],
    "val_precision": [
      0.7458893871444351,
      0.6996978851959519,
      0.7311608961298499,
      0.7415565345075319,
      0.727467811158278
    ],
    "val_recall": [
      0.6438709677415201,
      0.7470967741930664,
      0.694838709676971,
      0.651612903225386,
      0.6561290322576412
    ],
    "val_tp": [
      998,
      1158,
      1077,
      1010,
      1017
    ],
    "val_fp": [
      340,
      497,
      396,
      352,
      381
    ],
    "val_fn": [
      552,
      392,
      473,
      540,
      533
    ],
    "peak_memory_mb": [
      47824.8955078125,
      47825.0361328125,
      47825.0361328125,
      47825.0361328125,
      47825.0361328125
    ]
  }
}